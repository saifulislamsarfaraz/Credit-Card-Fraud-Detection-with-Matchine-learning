{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifulislamsarfaraz/Credit-Card-Fraud-Detection-with-Matchine-learning/blob/main/credit_card_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Credit Card Fraud Detection\n",
        "1.   Md Saiful(2019-2-60-040)\n",
        "2.   Wasif fuad khan(2019-2-60-004)\n",
        "3.   Ikra Tasnim Rimi(2019-2-60-009)\n",
        "4.   Khadija Akter(2018-2-60-009)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ae2cKB2DXRlx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbd2__F8u6U1"
      },
      "source": [
        "### Problem statement:-\n",
        "\n",
        "The aim of the project is to predict fraudulent credit card transactions using machine learning models. This is crucial from the bank’s as well as customer’s perspective. The banks cannot afford to lose their customers’ money to fraudsters. Every fraud is a loss to the bank as the bank is responsible for the fraud transactions.\n",
        "\n",
        "The dataset contains transactions made over a period of two days in September 2013 by European credit cardholders. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions. We need to take care of the data imbalance while building the model and come up with the best model by trying various algorithms."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Ddk5_-ITQelb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM2uDy9Su6U4"
      },
      "source": [
        "## Steps:-\n",
        "The steps are broadly divided into below steps. The sub steps are also listed while we approach each of the steps.\n",
        "1. Reading, understanding and visualising the data\n",
        "2. Preparing the data for modelling\n",
        "3. Building the model\n",
        "4. Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iINnHGpvD6X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g43Ol5VWu6U_"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_columns', 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-0zQPXfu6VF"
      },
      "source": [
        "# Exploratory data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bxf8Cw4Fu6VG"
      },
      "source": [
        "## Reading and understanding the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJT8RzWfu6VH"
      },
      "outputs": [],
      "source": [
        "# Reading the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/creditcard.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5Z1nxMfu6VN"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YI-oSgUu6VS"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxgZyGKvu6VX"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QApWSFWn77aK"
      },
      "outputs": [],
      "source": [
        "len(df.index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3iRER2cu6Vd"
      },
      "source": [
        "## Handling missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soiQvVSVu6Ve"
      },
      "source": [
        "#### Handling missing values in columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v52fVzbVu6Vf"
      },
      "outputs": [],
      "source": [
        "# Cheking percent of missing values in columns\n",
        "df_missing_columns = (round(((df.isnull().sum()/len(df.index))*100),2).to_frame('null')).sort_values('null', ascending=False)\n",
        "df_missing_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW8Myiwau6WV"
      },
      "source": [
        "We can see that there is no missing values in any of the columns. Hence, there is no problem with null values in the entire dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ya-zAvxdu6WX"
      },
      "source": [
        "### Checking the distribution of the classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZVwJXggu6Wa"
      },
      "outputs": [],
      "source": [
        "classes = df['Class'].value_counts()\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqVR11F2u6Wk"
      },
      "outputs": [],
      "source": [
        "normal_share = round((classes[0]/df['Class'].count()*100),2)\n",
        "normal_share"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJkpKiX_u6Wu"
      },
      "outputs": [],
      "source": [
        "fraud_share = round((classes[1]/df['Class'].count()*100),2)\n",
        "fraud_share\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gT9ENElu6XF"
      },
      "source": [
        "We can see that there is only 0.17% frauds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-pOhCEWKu6XG"
      },
      "outputs": [],
      "source": [
        "# Bar plot for the number of fraudulent vs non-fraudulent transcations\n",
        "sns.countplot(x='Class', data=df)\n",
        "plt.title('Number of fraudulent vs non-fraudulent transcations')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrNL8UKau6XV"
      },
      "outputs": [],
      "source": [
        "# Bar plot for the percentage of  fraudulent vs non-fraudulent transcations\n",
        "fraud_percentage = {'Class':['Non-Fraudulent', 'Fraudulent'], 'Percentage':[normal_share, fraud_share]} \n",
        "df_fraud_percentage = pd.DataFrame(fraud_percentage) \n",
        "sns.barplot(x='Class',y='Percentage', data=df_fraud_percentage)\n",
        "plt.title('Percentage of fraudulent vs non-fraudulent transcations')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4i9QZjAu6Xe"
      },
      "source": [
        "## Outliers treatment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are not performing any outliers treatment for this particular dataset. \n",
        "Because all the columns are already PCA transformed, which assumed that the outlier values are taken care while transforming the data."
      ],
      "metadata": {
        "id": "ni1rsKMzklwa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjP3ce_Au6Xn"
      },
      "source": [
        "### Observe the distribution of classes with time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bFe7Q01u6Xp"
      },
      "outputs": [],
      "source": [
        "# Creating fraudulent dataframe\n",
        "data_fraud = df[df['Class'] == 1]\n",
        "\n",
        "# Creating non fraudulent dataframe\n",
        "data_non_fraud = df[df['Class'] == 0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at9DGdfN_6SH"
      },
      "outputs": [],
      "source": [
        "data_non_fraud['Amount'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56mynziuEz1t"
      },
      "outputs": [],
      "source": [
        "data_fraud['Amount'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlfLB8_m-w77"
      },
      "outputs": [],
      "source": [
        "# data fraud plot\n",
        "data_fraud.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsziSExl-6yq"
      },
      "outputs": [],
      "source": [
        "data_non_fraud.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vq76AVf_u6Xw"
      },
      "outputs": [],
      "source": [
        "# Distribution plot\n",
        "plt.figure(figsize=(8,5))\n",
        "ax = sns.distplot(data_fraud['Time'],label='fraudulent',hist=False)\n",
        "ax = sns.distplot(data_non_fraud['Time'],label='non fraudulent',hist=False)\n",
        "ax.set(xlabel='Seconds elapsed between the transction and the first transction')\n",
        "plt.legend(['fraudulent', 'non fraudulent'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAW4QoScu6X2"
      },
      "source": [
        "##### Analysis\n",
        "We do not see any specific pattern for the fraudulent and non-fraudulent transctions with respect to Time.\n",
        "Hence, we can drop the `Time` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnT3BqXHu6X4"
      },
      "outputs": [],
      "source": [
        "# Dropping the Time column\n",
        "df.drop('Time', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm6gXB1Ou6YB"
      },
      "source": [
        "### Observe the distribution of classes with amount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxhBWt42u6YC"
      },
      "outputs": [],
      "source": [
        "# Distribution plot\n",
        "plt.figure(figsize=(8,5))\n",
        "ax = sns.distplot(data_fraud['Amount'],label='fraudulent',hist=False)\n",
        "ax = sns.distplot(data_non_fraud['Amount'],label='non fraudulent',hist=False)\n",
        "ax.set(xlabel='Transction Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD5k9ooZDTgM"
      },
      "outputs": [],
      "source": [
        "# Distribution plot\n",
        "plt.figure(figsize=(8,5))\n",
        "ax = sns.distplot(data_fraud['Amount'],label='fraudulent',hist=False)\n",
        "ax.set(xlabel='Transction Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zofvYB8qDXvA"
      },
      "outputs": [],
      "source": [
        "# Distribution plot\n",
        "plt.figure(figsize=(8,5))\n",
        "ax = sns.distplot(data_non_fraud['Amount'],label='non fraudulent',hist=False)\n",
        "ax.set(xlabel='Transction Amount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPisBCVFu6YI"
      },
      "source": [
        "##### Analysis\n",
        "We can see that the fraudulent transctions are mostly densed in the lower range of amount, whereas the non-fraudulent transctions are spreaded throughout low to high range of amount. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQ7CcJj5u6YK"
      },
      "source": [
        "## Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1t9AR81Mu6YL"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTvEou3eu6YS"
      },
      "outputs": [],
      "source": [
        "# Putting feature variables into X\n",
        "X = df.drop(['Class'], axis=1)\n",
        "#X.plot()\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBAoEhdKu6YY"
      },
      "outputs": [],
      "source": [
        "# Putting target variable to y\n",
        "y = df['Class']\n",
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT-JCXQCu6Yd"
      },
      "outputs": [],
      "source": [
        "# Splitting data into train and test set 80:20\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjBOOoRRu6Yi"
      },
      "source": [
        "## Feature Scaling\n",
        "We need to scale only the `Amount` column as all other columns are already scaled by the PCA transformation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzvfGrEau6Yj"
      },
      "outputs": [],
      "source": [
        "# Standardization method\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6MgJu5Yu6Yq"
      },
      "outputs": [],
      "source": [
        "# Instantiate the Scaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF9gCgoLu6Yy"
      },
      "outputs": [],
      "source": [
        "# Fit the data into scaler and transform\n",
        "X_train['Amount'] = scaler.fit_transform(X_train[['Amount']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3jOBWv5u6Y3"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPQlQ6CAu6Y8"
      },
      "source": [
        "##### Scaling the test set\n",
        "We don't fit scaler on the test set. We only transform the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNLTjaiu6Y9"
      },
      "outputs": [],
      "source": [
        "# Transform the test set\n",
        "X_test['Amount'] = scaler.transform(X_test[['Amount']])\n",
        "X_test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX6zSH6ju6ZC"
      },
      "source": [
        "## Checking the Skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lEY2C-gu6ZD"
      },
      "outputs": [],
      "source": [
        "# Listing the columns\n",
        "cols = X_train.columns\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_fIbyVu6ZM"
      },
      "outputs": [],
      "source": [
        "# Plotting the distribution of the variables (skewness) of all the columns\n",
        "k=0\n",
        "plt.figure(figsize=(17,28))\n",
        "for col in cols :    \n",
        "    k=k+1\n",
        "    plt.subplot(6, 5,k)    \n",
        "    sns.distplot(X_train[col])\n",
        "    plt.title(col+' '+str(X_train[col].skew()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2qcjquMu6ZU"
      },
      "source": [
        "We see that there are many variables, which are heavily skewed. We will mitigate the skewness only for those variables for bringing them into normal distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyT9p8Z_u6Zc"
      },
      "source": [
        "### Mitigate skweness with PowerTransformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLApGMuGu6Zd"
      },
      "outputs": [],
      "source": [
        "# Importing PowerTransformer\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "# Instantiate the powertransformer\n",
        "pt = PowerTransformer(method='yeo-johnson', standardize=True, copy=False)\n",
        "# Fit and transform the PT on training data\n",
        "X_train[cols] = pt.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq3JWqKku6Zr"
      },
      "outputs": [],
      "source": [
        "# Transform the test set\n",
        "X_test[cols] = pt.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gn9LGnIuu6Zz"
      },
      "outputs": [],
      "source": [
        "# Plotting the distribution of the variables (skewness) of all the columns\n",
        "k=0\n",
        "plt.figure(figsize=(17,28))\n",
        "for col in cols :    \n",
        "    k=k+1\n",
        "    plt.subplot(6, 5,k)    \n",
        "    sns.distplot(X_train[col])\n",
        "    plt.title(col+' '+str(X_train[col].skew()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG_PIa9cu6Z7"
      },
      "source": [
        "Now we can see that all the variables are normally distributed after the transformation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN3HKn_vu6Z8"
      },
      "source": [
        "# Model building on imbalanced data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfRG9UwjL5GU"
      },
      "source": [
        "### Metric selection for heavily imbalanced data\n",
        "As we have seen that the data is heavily imbalanced, where only 0.17% transctions are fraudulent, we should not consider Accuracy as a good measure for evaluating the model. Because in the case of all the datapoints return a particular class(1/0) irrespective of any prediction, still the model will result more than 99% Accuracy.\n",
        "\n",
        "Hence, we have to measure the ROC-AUC score for fair evaluation of the model. The ROC curve is used to understand the strength of the model by evaluating the performance of the model at all the classification thresholds. The default threshold of 0.5 is not always the ideal threshold to find the best classification label of the test point. Because the ROC curve is measured at all thresholds, the best threshold would be one at which the TPR is high and FPR is low, i.e., misclassifications are low. After determining the optimal threshold, we can calculate the F1 score of the classifier to measure the precision and recall at the selected threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W-CZRb7L5GU"
      },
      "source": [
        "#### Why SVM was not tried for model building and Random Forest was not tried for few cases?\n",
        "In the dataset we have 284807 datapoints and in the case of Oversampling we would have even more number of datapoints. SVM is not very efficient with large number of datapoints beacuse it takes lot of computational power and resources to make the transformation. When we perform the cross validation with K-Fold for hyperparameter tuning, it takes lot of computational resources and it is very time consuming. Hence, because of the unavailablity of the required resources and time SVM was not tried.\n",
        "\n",
        "For the same reason Random forest was also not tried for model building in few of the hyperparameter tuning for oversampling technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0v_ynJiL5GU"
      },
      "source": [
        "#### Why KNN was not used for model building?\n",
        "KNN is not memory efficient. It becomes very slow as the number of datapoints increases as the model needs to store all the data points. It is computationally heavy because for a single datapoint the algorithm has to calculate the distance of all the datapoints and find the nearest neighbors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1ZC72gpu6Z-"
      },
      "source": [
        "### Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkswPEwBu6Z_"
      },
      "outputs": [],
      "source": [
        "# Importing scikit logistic regression module\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R-pakFmu6aE"
      },
      "outputs": [],
      "source": [
        "# Impoting metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comrNu0yu6aJ"
      },
      "source": [
        "#### Tuning hyperparameter  C\n",
        "C is the the inverse of regularization strength in Logistic Regression. Higher values of C correspond to less regularization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juSQ7kHxu6aK"
      },
      "outputs": [],
      "source": [
        "# Importing libraries for cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTvEVU6Uu6aQ"
      },
      "outputs": [],
      "source": [
        "# Creating KFold object with 5 splits\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
        "\n",
        "# Specify params\n",
        "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Specifing score as recall as we are more focused on acheiving the higher sensitivity than the accuracy\n",
        "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
        "                        param_grid = params, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True) \n",
        "\n",
        "# Fit the model\n",
        "model_cv.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1srhQzaPu6aZ"
      },
      "outputs": [],
      "source": [
        "# results of grid search CV\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQHPJncVu6af"
      },
      "outputs": [],
      "source": [
        "# plot of C versus train and validation scores\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc')\n",
        "plt.legend(['test result', 'train result'], loc='upper left')\n",
        "plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2WOKQIuu6ap"
      },
      "outputs": [],
      "source": [
        "# Best score with best C\n",
        "best_score = model_cv.best_score_\n",
        "best_C = model_cv.best_params_['C']\n",
        "\n",
        "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDh_h9P7u6ay"
      },
      "source": [
        "#### Logistic regression with optimal C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4iUliVvu6a0"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model with best C\n",
        "logistic_imb = LogisticRegression(C=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEPWrysIu6a7"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the train set\n",
        "logistic_imb_model = logistic_imb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGre5jWku6ba"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmHmFtRdu6bc"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = logistic_imb_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH2_OXo2u6bh"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXhDRhYDu6bm"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb5nfmExu6bu"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STSpclRdL5GW"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQhL6zC_u6by"
      },
      "source": [
        "##### ROC on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqQli61Gu6bz"
      },
      "outputs": [],
      "source": [
        "# ROC Curve function\n",
        "\n",
        "def draw_roc( actual, probs ):\n",
        "    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n",
        "                                              drop_intermediate = False )\n",
        "    auc_score = metrics.roc_auc_score( actual, probs )\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic example')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3lsDBWDu6b7"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = logistic_imb_model.predict_proba(X_train)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTt47Imiu6cE"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwomdpwcu6cJ"
      },
      "source": [
        "We acheived very good ROC 0.99 on the train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z61H8NcIu6cL"
      },
      "source": [
        "#### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCzUiIIHu6cM"
      },
      "outputs": [],
      "source": [
        "# Prediction on the test set\n",
        "y_test_pred = logistic_imb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rta2aGEku6cT"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "Ni0oL2jZY-r5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILfPTUnVu6cc"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyVM_U_Eu6ch"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krun52j7L5GY"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHufzVLeu6cm"
      },
      "source": [
        "##### ROC on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65bwEos7u6cm"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = logistic_imb_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NGDwjyau6cq"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNVtUmj2u6cv"
      },
      "source": [
        "We can see that we have very good ROC on the test set 0.97, which is almost close to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npP3Sjspu6cw"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.70\n",
        "    - Specificity = 0.99\n",
        "    - F1-Score = 0.76\n",
        "    - ROC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.77\n",
        "    - Specificity = 0.99\n",
        "    - F1-Score = 0.65\n",
        "    - ROC = 0.97\n",
        "\n",
        "Overall, the model is performing well in the test set, what it had learnt from the train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMQ3LVL2u6cx"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aHdB0CHSsagE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVaOVLGTu6cx"
      },
      "outputs": [],
      "source": [
        "# Importing XGBoost\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBzFkTiwu6c2"
      },
      "source": [
        "##### Tuning the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eesdL5dLu6c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ab98b4-6beb-4b62-9ea9-fa06f89ec424"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
          ]
        }
      ],
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 3\n",
        "\n",
        "# specify range of hyperparameters\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train, y_train)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbjPR_wgu6c6"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n_HBqkS7vFWM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfUn8kJ6u6c9"
      },
      "outputs": [],
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]} \n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "    \n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdIyusKeu6dA"
      },
      "source": [
        "##### Model with optimal hyperparameters\n",
        "We see that the train score almost touches to 1. Among the hyperparameters, we can choose the best parameters as learning_rate : 0.2 and subsample: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIHTe9iGu6dA"
      },
      "outputs": [],
      "source": [
        "model_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZWn61VWu6dD"
      },
      "outputs": [],
      "source": [
        "# chosen hyperparameters\n",
        "# 'objective':'binary:logistic' outputs probability rather than label, which we need for calculating auc\n",
        "params = {'learning_rate': 0.2,\n",
        "          'max_depth': 2, \n",
        "          'n_estimators':200,\n",
        "          'subsample':0.9,\n",
        "         'objective':'binary:logistic'}\n",
        "\n",
        "# fit model on training data\n",
        "xgb_imb_model = XGBClassifier(params = params)\n",
        "xgb_imb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UWm75lMJu6dF"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ftImmA-u6dF"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = xgb_imb_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIbppSpyu6dJ"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVOJFGv5u6dN"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWCn7cBTu6dT"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cn9fD2AL5Ga"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-xWIPUQu6dW"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba_imb_xgb = xgb_imb_model.predict_proba(X_train)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WrajBKSu6dZ"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train, y_train_pred_proba_imb_xgb)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-7hX9OUL5Gb"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train, y_train_pred_proba_imb_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "421AFLmmu6dd"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97fAvuBSu6de"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = xgb_imb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNIsCGbfu6dh"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3a8YNlJu6dl"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCgfikWxu6dp"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrWg3xOyL5Gb"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iPpaLtDu6ds"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = xgb_imb_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwSGPvnqu6dv"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6rN2SDZL5Gc"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm23el46u6dx"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.85\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.99\n",
        "    - F1-Score = 0.90\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.75\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.98\n",
        "    - F-Score = 0.79\n",
        "\n",
        "Overall, the model is performing well in the test set, what it had learnt from the train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj4qybydu6dy"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pacANTsyu6dy"
      },
      "outputs": [],
      "source": [
        "# Importing decision tree classifier\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xf10KIeSu6d2"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid \n",
        "param_grid = {\n",
        "    'max_depth': range(5, 15, 5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the grid search model\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator = dtree, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 3, \n",
        "                           verbose = 1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "keumhyPCu6d8"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O0n7PR7u6eA"
      },
      "outputs": [],
      "source": [
        "# Printing the optimal sensitivity score and hyperparameters\n",
        "print(\"Best roc_auc:-\", grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHH22W7Au6eE"
      },
      "outputs": [],
      "source": [
        "# Model with optimal hyperparameters\n",
        "dt_imb_model = DecisionTreeClassifier(criterion = \"gini\", \n",
        "                                  random_state = 100,\n",
        "                                  max_depth=5, \n",
        "                                  min_samples_leaf=100,\n",
        "                                  min_samples_split=100)\n",
        "\n",
        "dt_imb_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teEhvb4pu6eH"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AWP9dsuu6eH"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = dt_imb_model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mA42jj0uu6eJ"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train, y_train)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hiYzaGIu6eM"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNfGD46ku6eO"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOFBq0BIL5Gd"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4AzB2jYu6eQ"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = dt_imb_model.predict_proba(X_train)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WV2xY0dhu6eT"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDrVtqR3L5Ge"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train, y_train_pred_proba)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXblPUcyu6eV"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drgvh5S-u6eW"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = dt_imb_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lmZszZdu6eY"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xnFAIS4u6eb"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMb4H8n2u6ed"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFJJUNh0L5Ge"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id8aFm_Mu6ef"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = dt_imb_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af7a5a4mu6ek"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK4G0oNpL5Gf"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkWkHso_u6en"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 1.0\n",
        "    - F1-Score = 0.75\n",
        "    - ROC-AUC = 0.95\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.58\n",
        "    - Specificity = 0.99\n",
        "    - F-1 Score = 0.75\n",
        "    - ROC-AUC = 0.92\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOTr0mCTL5Gi"
      },
      "source": [
        "### Choosing best model on the imbalanced data\n",
        "\n",
        "We can see that among all the models we tried (Logistic, XGBoost, Decision Tree, and Random Forest), almost all of them have performed well. More specifically Logistic regression and XGBoost performed best in terms of ROC-AUC score.\n",
        "\n",
        "But as we have to choose one of them, we can go for the best as `XGBoost`, which gives us ROC score of 1.0 on the train data and 0.98 on the test data.\n",
        "\n",
        "Keep in mind that XGBoost requires more resource utilization than Logistic model. Hence building XGBoost model is more costlier than the Logistic model. But XGBoost having ROC score 0.98, which is 0.01 more than the Logistic model. The 0.01 increase of score may convert into huge amount of saving for the bank."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNdhrQEku6ex"
      },
      "source": [
        "#### Print the important features of the best model to understand the dataset\n",
        "- This will not give much explanation on the already transformed dataset\n",
        "- But it will help us in understanding if the dataset is not PCA transformed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fy-30Oxu6ex",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Features of XGBoost model\n",
        "\n",
        "var_imp = []\n",
        "for i in xgb_imb_model.feature_importances_:\n",
        "    var_imp.append(i)\n",
        "print('Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-1])+1)\n",
        "print('2nd Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-2])+1)\n",
        "print('3rd Top var =', var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-3])+1)\n",
        "# Variable on Index-16 and Index-13 seems to be the top 2 variables\n",
        "top_var_index = var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-1])\n",
        "second_top_var_index = var_imp.index(np.sort(xgb_imb_model.feature_importances_)[-2])\n",
        "\n",
        "X_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\n",
        "X_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n",
        "\n",
        "np.random.shuffle(X_train_0)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [20, 20]\n",
        "\n",
        "plt.scatter(X_train_1[:, top_var_index], X_train_1[:, second_top_var_index], label='Actual Class-1 Examples')\n",
        "plt.scatter(X_train_0[:X_train_1.shape[0], top_var_index], X_train_0[:X_train_1.shape[0], second_top_var_index],\n",
        "            label='Actual Class-0 Examples')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpqYyzSiL5Gj"
      },
      "source": [
        "#### Print the FPR,TPR & select the best threshold from the roc curve for the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BffUwkPWL5Gj"
      },
      "outputs": [],
      "source": [
        "print('Train auc =', metrics.roc_auc_score(y_train, y_train_pred_proba_imb_xgb))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_pred_proba_imb_xgb)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(\"Threshold=\",threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdg-xdtOL5Gj"
      },
      "source": [
        "We can see that the threshold is 0.85, for which the TPR is the highest and FPR is the lowest and we got the best ROC score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCmLWLP3u6ez"
      },
      "source": [
        "# Handling data imbalance\n",
        "As we see that the data is heavily imbalanced, We will try several approaches for handling data imbalance.\n",
        "\n",
        "- Undersampling :- Here for balancing the class distribution, the non-fraudulent transctions count will be reduced to 396 (similar count of fraudulent transctions)\n",
        "- Oversampling :- Here we will make the same count of non-fraudulent transctions as fraudulent transctions.\n",
        "- SMOTE :- Synthetic minority oversampling technique. It is another oversampling technique, which uses nearest neighbor algorithm to create synthetic data. \n",
        "- Adasyn:- This is similar to SMOTE with minor changes that the new synthetic data is generated on the region of low density of imbalanced data points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ijYmXCVL5Gj"
      },
      "source": [
        "## Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93Xw-uRvL5Gj"
      },
      "outputs": [],
      "source": [
        "# Importing undersampler library\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmkbxXHoL5Gj"
      },
      "outputs": [],
      "source": [
        "# instantiating the random undersampler \n",
        "rus = RandomUnderSampler()\n",
        "# resampling X, y\n",
        "X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw91lpqmL5Gj"
      },
      "outputs": [],
      "source": [
        "# Befor sampling class distribution\n",
        "print('Before sampling class distribution:-',Counter(y_train))\n",
        "# new class distribution \n",
        "print('New class distribution:-',Counter(y_train_rus))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M3L_IIzL5Gj"
      },
      "source": [
        "## Model building on balanced data with Undersampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kpLV05Nu6e7"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGwJYAnFu6e7"
      },
      "outputs": [],
      "source": [
        "# Creating KFold object with 5 splits\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
        "\n",
        "# Specify params\n",
        "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Specifing score as roc-auc\n",
        "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
        "                        param_grid = params, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True) \n",
        "\n",
        "# Fit the model\n",
        "model_cv.fit(X_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHfzDM8-u6e-"
      },
      "outputs": [],
      "source": [
        "# results of grid search CV\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gKV1AFBu6fA"
      },
      "outputs": [],
      "source": [
        "# plot of C versus train and validation scores\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc')\n",
        "plt.legend(['test result', 'train result'], loc='upper left')\n",
        "plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apRtQCMUu6fC"
      },
      "outputs": [],
      "source": [
        "# Best score with best C\n",
        "best_score = model_cv.best_score_\n",
        "best_C = model_cv.best_params_['C']\n",
        "\n",
        "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM6XPcYou6fE"
      },
      "source": [
        "#### Logistic regression with optimal C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRH9hS1Uu6fF"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model with best C\n",
        "logistic_bal_rus = LogisticRegression(C=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEhVwDdAu6fM"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the train set\n",
        "logistic_bal_rus_model = logistic_bal_rus.fit(X_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQjhIW5bu6fO"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-jFPoYuu6fP"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = logistic_bal_rus_model.predict(X_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg8TwvIKu6fT"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_rus, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuG-_iuLu6fV"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdgIWRmnu6fX"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_rus, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFqf1tmrL5Gl"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxhNfX2Ju6fZ"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = logistic_bal_rus_model.predict_proba(X_train_rus)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXVcKRRvL5Gl"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_rus, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibTIEyP1L5Gl"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_rus, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDTxEMlu6fe"
      },
      "source": [
        "#### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSiFXc-8u6fe"
      },
      "outputs": [],
      "source": [
        "# Prediction on the test set\n",
        "y_test_pred = logistic_bal_rus_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHLC0ShJu6fg"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "447RMBsju6fj"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_blYsnYHu6fl"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8u983fWL5Gm"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4OJS_yGu6fn"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = logistic_bal_rus_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAi6AFF1L5Gm"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUcG7gP1L5Gm"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z9HOVOZu6fr"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.95\n",
        "    - Sensitivity = 0.92\n",
        "    - Specificity = 0.98\n",
        "    - ROC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.97\n",
        "    - Sensitivity = 0.86\n",
        "    - Specificity = 0.97\n",
        "    - ROC = 0.96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6RacuWOu6fr"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ipH43n7u6fs"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 3\n",
        "\n",
        "# specify range of hyperparameters\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train_rus, y_train_rus)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqtNDRCru6fu"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7jZAuITu6fw"
      },
      "outputs": [],
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]} \n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "    \n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAFNtBuPu6fz"
      },
      "source": [
        "##### Model with optimal hyperparameters\n",
        "We see that the train score almost touches to 1. Among the hyperparameters, we can choose the best parameters as learning_rate : 0.2 and subsample: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVmu6fXmu6fz"
      },
      "outputs": [],
      "source": [
        "model_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TVuMmyiu6f1"
      },
      "outputs": [],
      "source": [
        "# chosen hyperparameters\n",
        "# 'objective':'binary:logistic' outputs probability rather than label, which we need for calculating auc\n",
        "params = {'learning_rate': 0.2,\n",
        "          'max_depth': 2, \n",
        "          'n_estimators':200,\n",
        "          'subsample':0.6,\n",
        "         'objective':'binary:logistic'}\n",
        "\n",
        "# fit model on training data\n",
        "xgb_bal_rus_model = XGBClassifier(params = params)\n",
        "xgb_bal_rus_model.fit(X_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYtBq02Ou6f3"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNkEAenVu6f4"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = xgb_bal_rus_model.predict(X_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0bPnnu5u6f5"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_rus, y_train_rus)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PvSu3Yqu6f8"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xy1ZlzQLu6gB"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_rus, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsP0-LnvL5Go"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMrHBVmpu6gF"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = xgb_bal_rus_model.predict_proba(X_train_rus)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7fbi4cIu6gJ"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_rus, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5A8pLrvL5Go"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_rus, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrqYt9yLu6gL"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ytucRT6u6gL"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = xgb_bal_rus_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mG6dUlYu6gN"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf2FBaRzu6gR"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7o9WTsmu6gX"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB377wxeL5Gp"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyGh662Wu6ga"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = xgb_bal_rus_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EagOOrZau6ge"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI791x5VL5Gp"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REAVz2ozu6gg"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 1.0\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 1.0\n",
        "    - ROC-AUC = 1.0\n",
        "- Test set\n",
        "    - Accuracy = 0.96\n",
        "    - Sensitivity = 0.92\n",
        "    - Specificity = 0.96\n",
        "    - ROC-AUC = 0.98"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivgx2m8Iu6gg"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np-MAFBJu6gg"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid \n",
        "param_grid = {\n",
        "    'max_depth': range(5, 15, 5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the grid search model\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator = dtree, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 3, \n",
        "                           verbose = 1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_rus,y_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHCoQp7Qu6gk"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IhZW0mIu6gm"
      },
      "outputs": [],
      "source": [
        "# Printing the optimal sensitivity score and hyperparameters\n",
        "print(\"Best roc_auc:-\", grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDqFdCAbu6gp"
      },
      "outputs": [],
      "source": [
        "# Model with optimal hyperparameters\n",
        "dt_bal_rus_model = DecisionTreeClassifier(criterion = \"gini\", \n",
        "                                  random_state = 100,\n",
        "                                  max_depth=5, \n",
        "                                  min_samples_leaf=50,\n",
        "                                  min_samples_split=50)\n",
        "\n",
        "dt_bal_rus_model.fit(X_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_qgKGbAu6gr"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S0txFg_u6gr"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = dt_bal_rus_model.predict(X_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nl0tnIQu6gt"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_rus, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xQX4Xnru6gv"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egC2eSinu6gz"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_rus, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCe64z2PL5Gq"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbxHbSJlu6g1"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = dt_bal_rus_model.predict_proba(X_train_rus)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lG-ObwWRu6g2"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_rus, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmDw5qXSL5Gr"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_rus, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFnRPAL8u6g9"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yu1U7m1Ku6g-"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = dt_bal_rus_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwUL0xovu6hB"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_EptjEZu6hD"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vf2kQHGu6hF"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSAtm-A8L5Gr"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3Txsz_su6hH"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = dt_bal_rus_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJkXgHtnu6hI"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uTBO3gqL5Gs"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4IZVceou6hK"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.93\n",
        "    - Sensitivity = 0.88\n",
        "    - Specificity = 0.97\n",
        "    - ROC-AUC = 0.98\n",
        "- Test set\n",
        "    - Accuracy = 0.96\n",
        "    - Sensitivity = 0.85\n",
        "    - Specificity = 0.96\n",
        "    - ROC-AUC = 0.96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZgGINh903AT"
      },
      "source": [
        "### Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0FcUjT703Am"
      },
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    'max_depth': range(5,10,5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "    'n_estimators': [100,200,300], \n",
        "    'max_features': [10, 20]\n",
        "}\n",
        "# Create a based model\n",
        "rf = RandomForestClassifier()\n",
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = rf, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 2,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1, \n",
        "                           return_train_score=True)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train_rus, y_train_rus)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ6FrsT703At"
      },
      "outputs": [],
      "source": [
        "# printing the optimal accuracy score and hyperparameters\n",
        "print('We can get roc-auc of',grid_search.best_score_,'using',grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY97Ncl703Ay"
      },
      "outputs": [],
      "source": [
        "# model with the best hyperparameters\n",
        "\n",
        "rfc_bal_rus_model = RandomForestClassifier(bootstrap=True,\n",
        "                             max_depth=5,\n",
        "                             min_samples_leaf=50, \n",
        "                             min_samples_split=50,\n",
        "                             max_features=10,\n",
        "                             n_estimators=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luhUjWoP03A2"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "rfc_bal_rus_model.fit(X_train_rus, y_train_rus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xYcjFMP03BB"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMZ5JZGp03BC"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = rfc_bal_rus_model.predict(X_train_rus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzK3SRYZ03BF"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_rus, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAEbFW2j03BK"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLCJ7dtj03BN"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_rus, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGgGsqWRL5Gt"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_rus, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqUuggNn03BQ"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = rfc_bal_rus_model.predict_proba(X_train_rus)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYGlvIPc03BU"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_rus, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLZ1zDflL5Gt"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_rus, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCWFhkrH03BX"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lb145DuR03BX"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = rfc_bal_rus_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvQaY_V803Bb"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JB2O-lhq03Bf"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQuNUr_e03Bi"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2xj4I3RL5Gu"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7ii-X4N03Bl"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = rfc_bal_rus_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntZp7y0703Bp"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcg3geXBL5Gu"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyoY29bj03Bt"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.94\n",
        "    - Sensitivity = 0.89\n",
        "    - Specificity = 0.98\n",
        "    - ROC-AUC = 0.98\n",
        "- Test set\n",
        "    - Accuracy = 0.98\n",
        "    - Sensitivity = 0.83\n",
        "    - Specificity = 0.98\n",
        "    - ROC-AUC = 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuGoaRxyL5Gu"
      },
      "source": [
        "# Oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNE3xBeVL5Gu"
      },
      "outputs": [],
      "source": [
        "# Importing oversampler library\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ8tfDnfL5Gu"
      },
      "outputs": [],
      "source": [
        "# instantiating the random oversampler \n",
        "ros = RandomOverSampler()\n",
        "# resampling X, y\n",
        "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BREgDnO2L5Gv"
      },
      "outputs": [],
      "source": [
        "# Befor sampling class distribution\n",
        "print('Before sampling class distribution:-',Counter(y_train))\n",
        "# new class distribution \n",
        "print('New class distribution:-',Counter(y_train_ros))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnQDpy9YL5Gv"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYdlE44QL5Gv"
      },
      "outputs": [],
      "source": [
        "# Creating KFold object with 5 splits\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
        "\n",
        "# Specify params\n",
        "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Specifing score as roc-auc\n",
        "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
        "                        param_grid = params, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True) \n",
        "\n",
        "# Fit the model\n",
        "model_cv.fit(X_train_ros, y_train_ros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8FbTj7NL5Gv"
      },
      "outputs": [],
      "source": [
        "# results of grid search CV\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wOCRkbPL5Gv"
      },
      "outputs": [],
      "source": [
        "# plot of C versus train and validation scores\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc')\n",
        "plt.legend(['test result', 'train result'], loc='upper left')\n",
        "plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOxGw7bJL5Gv"
      },
      "outputs": [],
      "source": [
        "# Best score with best C\n",
        "best_score = model_cv.best_score_\n",
        "best_C = model_cv.best_params_['C']\n",
        "\n",
        "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2Wwf_E8L5Gv"
      },
      "source": [
        "#### Logistic regression with optimal C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjn1xPCtL5Gv"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model with best C\n",
        "logistic_bal_ros = LogisticRegression(C=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Saq60L66L5Gv"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the train set\n",
        "logistic_bal_ros_model = logistic_bal_ros.fit(X_train_ros, y_train_ros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPRnHi9CL5Gw"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YY8d71RL5Gw"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = logistic_bal_ros_model.predict(X_train_ros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oA7eHKNL5Gw"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_ros, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-xzNlZbL5Gw"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAbpt1krL5Gw"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_ros, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train_ros, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZ8KiKrcL5Gw"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_ros, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rO8PIjqIL5Gw"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = logistic_bal_ros_model.predict_proba(X_train_ros)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5PFR5naL5Gw"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_ros, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiljRPXOL5Gw"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_ros, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIQxTS0sL5Gx"
      },
      "source": [
        "#### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtMcos9LL5Gx"
      },
      "outputs": [],
      "source": [
        "# Prediction on the test set\n",
        "y_test_pred = logistic_bal_ros_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwauzLg8L5Gx"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDPg8t6UL5Gx"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AU-N5-czL5Gx"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEQkOXNiL5Gx"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVeEMZx5L5Gz"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = logistic_bal_ros_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3U9FcoyL5Gz"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iftlmGYdL5Gz"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bscvkUd9L5Gz"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.95\n",
        "    - Sensitivity = 0.92\n",
        "    - Specificity = 0.97\n",
        "    - ROC = 0.98\n",
        "- Test set\n",
        "    - Accuracy = 0.97\n",
        "    - Sensitivity = 0.89\n",
        "    - Specificity = 0.97\n",
        "    - ROC = 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryfKw-UdL5Gz"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmDGb0kCL5G0"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 3\n",
        "\n",
        "# specify range of hyperparameters\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train_ros, y_train_ros)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__uL9uHzL5G0"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSua3XPDL5G0"
      },
      "outputs": [],
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]} \n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "    \n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXjaoFfnL5G0"
      },
      "source": [
        "##### Model with optimal hyperparameters\n",
        "We see that the train score almost touches to 1. Among the hyperparameters, we can choose the best parameters as learning_rate : 0.2 and subsample: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4vFwKQxL5G0"
      },
      "outputs": [],
      "source": [
        "model_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBWl9NgRL5G0"
      },
      "outputs": [],
      "source": [
        "# chosen hyperparameters\n",
        "params = {'learning_rate': 0.6,\n",
        "          'max_depth': 2, \n",
        "          'n_estimators':200,\n",
        "          'subsample':0.9,\n",
        "         'objective':'binary:logistic'}\n",
        "\n",
        "# fit model on training data\n",
        "xgb_bal_ros_model = XGBClassifier(params = params)\n",
        "xgb_bal_ros_model.fit(X_train_ros, y_train_ros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRK4YFGcL5G0"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LopxS6fvL5G0"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = xgb_bal_ros_model.predict(X_train_ros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_Gj6ZwWL5G0"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_ros, y_train_ros)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8uBA1fSL5G1"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "050ATiKZL5G1"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_ros, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x_ms0FQL5G1"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_ros, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utPSH3i2L5G1"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = xgb_bal_ros_model.predict_proba(X_train_ros)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYl4YfwxL5G1"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_ros, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmEQPxj-L5G1"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_ros, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WboT6F8L5G1"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6eWL1nGL5G1"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = xgb_bal_ros_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pq1ifAtAL5G1"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA-g8XcdL5G2"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHaM2CJ0L5G2"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7m3COneJL5G2"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uli9OzqL5G2"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = xgb_bal_ros_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bz68qzkL5G2"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VUdf8xAL5G2"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqih-5tgL5G2"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 1.0\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 1.0\n",
        "    - ROC-AUC = 1.0\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.80\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KOlqxlZL5G2"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEt3r0L1L5G2"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid \n",
        "param_grid = {\n",
        "    'max_depth': range(5, 15, 5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the grid search model\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator = dtree, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 3, \n",
        "                           verbose = 1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_ros,y_train_ros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UeyOPBHL5G3"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ju-abCH7YjzH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJNzh5LJL5G3"
      },
      "outputs": [],
      "source": [
        "# Printing the optimal sensitivity score and hyperparameters\n",
        "print(\"Best roc_auc:-\", grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFwF-mbNL5G3"
      },
      "outputs": [],
      "source": [
        "# Model with optimal hyperparameters\n",
        "dt_bal_ros_model = DecisionTreeClassifier(criterion = \"gini\", \n",
        "                                  random_state = 100,\n",
        "                                  max_depth=10, \n",
        "                                  min_samples_leaf=100,\n",
        "                                  min_samples_split=50)\n",
        "\n",
        "dt_bal_ros_model.fit(X_train_ros, y_train_ros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dTCT6B6L5G3"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCtyw0hzL5G3"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = dt_bal_ros_model.predict(X_train_ros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFxqwr5oL5G3"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_ros, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JowPfqV9L5G3"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Sp0ZDHCL5G3"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_ros, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKULmMvoL5G3"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_ros, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuPdJwmdL5G4"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = dt_bal_ros_model.predict_proba(X_train_ros)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSIXoa0gL5G4"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_ros, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TlHfrsEL5G4"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_ros, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ry1RGdXL5G4"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnyXzks5L5G4"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = dt_bal_ros_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPDlS2WxL5G4"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJ6WTNsJL5G4"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0aEGQneL5G4"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdxUH8PnL5G4"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VqRDOxEwL5G4"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = dt_bal_ros_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tRxe8tGL5G5"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8Ta9pdOL5G5"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTjt--yYL5G5"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.79\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBToeNlXL5G5"
      },
      "source": [
        "## SMOTE (Synthetic Minority Oversampling Technique)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCOu6c80u6e0"
      },
      "source": [
        "We are creating synthetic samples by doing upsampling using SMOTE(Synthetic Minority Oversampling Technique)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z0_Q0Pwu6e0"
      },
      "outputs": [],
      "source": [
        "# Importing SMOTE\n",
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOY7lSfAu6e2"
      },
      "outputs": [],
      "source": [
        "# Instantiate SMOTE\n",
        "sm = SMOTE(random_state=27)\n",
        "# Fitting SMOTE to the train set\n",
        "X_train_smote, y_train_smote = sm.fit_sample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tbz5qMZu6e4"
      },
      "outputs": [],
      "source": [
        "print('Before SMOTE oversampling X_train shape=',X_train.shape)\n",
        "print('After SMOTE oversampling X_train shape=',X_train_smote.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYGjuRlYL5G5"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drEjMHbxL5G5"
      },
      "outputs": [],
      "source": [
        "# Creating KFold object with 5 splits\n",
        "folds = KFold(n_splits=5, shuffle=True, random_state=4)\n",
        "\n",
        "# Specify params\n",
        "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Specifing score as roc-auc\n",
        "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
        "                        param_grid = params, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True) \n",
        "\n",
        "# Fit the model\n",
        "model_cv.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xKQHW2BL5G6"
      },
      "outputs": [],
      "source": [
        "# results of grid search CV\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qaJGvM7rL5G6"
      },
      "outputs": [],
      "source": [
        "# plot of C versus train and validation scores\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc')\n",
        "plt.legend(['test result', 'train result'], loc='upper left')\n",
        "plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crjYZvnNL5G6"
      },
      "outputs": [],
      "source": [
        "# Best score with best C\n",
        "best_score = model_cv.best_score_\n",
        "best_C = model_cv.best_params_['C']\n",
        "\n",
        "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIFCgAVQL5G6"
      },
      "source": [
        "#### Logistic regression with optimal C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KfUyqMjL5G6"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model with best C\n",
        "logistic_bal_smote = LogisticRegression(C=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro2bful8L5G6"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the train set\n",
        "logistic_bal_smote_model = logistic_bal_smote.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo-v9f6LL5G6"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4io1rmtWL5G6"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = logistic_bal_smote_model.predict(X_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRp7OXJvL5G6"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_smote, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S2TkmWeL5G7"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIDuKy_PL5G7"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_smote, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIxCA5ZZL5G7"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_smote, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR0LLKeKL5G7"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba_log_bal_smote = logistic_bal_smote_model.predict_proba(X_train_smote)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f97Js40ju6fb"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_smote, y_train_pred_proba_log_bal_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thil7RGQL5G7"
      },
      "source": [
        "#### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G77GYdhUL5G7"
      },
      "outputs": [],
      "source": [
        "# Prediction on the test set\n",
        "y_test_pred = logistic_bal_smote_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xi_4COcLL5G7"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM2UN60WL5G7"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ2kQ4y0L5G7"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjcPYy9VL5G8"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLNLsRMJu6fm"
      },
      "source": [
        "##### ROC on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EqfvF1eL5G8"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = logistic_bal_smote_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34vEw73yu6fp"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKR5K0AqL5G8"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.95\n",
        "    - Sensitivity = 0.92\n",
        "    - Specificity = 0.98\n",
        "    - ROC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.97\n",
        "    - Sensitivity = 0.90\n",
        "    - Specificity = 0.99\n",
        "    - ROC = 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu_ZSGP2L5G8"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4jZOYMYL5G8"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 3\n",
        "\n",
        "# specify range of hyperparameters\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train_smote, y_train_smote)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwFH822ZL5G8"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySeSuYuEL5G8"
      },
      "outputs": [],
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]} \n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "    \n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHfDb-lWL5G9"
      },
      "source": [
        "##### Model with optimal hyperparameters\n",
        "We see that the train score almost touches to 1. Among the hyperparameters, we can choose the best parameters as learning_rate : 0.2 and subsample: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ISkEvOQuL5G9"
      },
      "outputs": [],
      "source": [
        "model_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CdTGmR6L5G9"
      },
      "outputs": [],
      "source": [
        "# chosen hyperparameters\n",
        "# 'objective':'binary:logistic' outputs probability rather than label, which we need for calculating auc\n",
        "params = {'learning_rate': 0.6,\n",
        "          'max_depth': 2, \n",
        "          'n_estimators':200,\n",
        "          'subsample':0.9,\n",
        "         'objective':'binary:logistic'}\n",
        "\n",
        "# fit model on training data\n",
        "xgb_bal_smote_model = XGBClassifier(params = params)\n",
        "xgb_bal_smote_model.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh1LBOprL5G9"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-EE4fqgL5G9"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = xgb_bal_smote_model.predict(X_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIIwzOq7L5G9"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_smote, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HKDbMN-fL5G9"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1MJo9jSL5G-"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_smote, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW_PoB2HL5G-"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_smote, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0tccB6RL5G-"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = xgb_bal_smote_model.predict_proba(X_train_smote)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnHxFX23L5G-"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_smote, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzaSPpP3L5G-"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_smote, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yF8SqqvbL5G-"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S6LAIo2L5G-"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = xgb_bal_smote_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDtwkLrkL5G-"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TOLpUN8L5G-"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTgAOwxML5G_"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpFQAB0CL5G_"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n32UKTAbL5G_"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = xgb_bal_smote_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE115MvbL5G_"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpirmeDFL5G_"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqY-O1lzL5G_"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 1.0\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.79\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.96\n",
        "\n",
        "Overall, the model is performing well in the test set, what it had learnt from the train set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVSxH0ulL5G_"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DIZX5CkL5G_"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid \n",
        "param_grid = {\n",
        "    'max_depth': range(5, 15, 5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the grid search model\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator = dtree, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 3, \n",
        "                           verbose = 1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_smote,y_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8PXlxCnL5G_"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IS9m6xNPL5G_"
      },
      "outputs": [],
      "source": [
        "# Printing the optimal sensitivity score and hyperparameters\n",
        "print(\"Best roc_auc:-\", grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ly3ycJ_dL5HA"
      },
      "outputs": [],
      "source": [
        "# Model with optimal hyperparameters\n",
        "dt_bal_smote_model = DecisionTreeClassifier(criterion = \"gini\", \n",
        "                                  random_state = 100,\n",
        "                                  max_depth=10, \n",
        "                                  min_samples_leaf=50,\n",
        "                                  min_samples_split=100)\n",
        "\n",
        "dt_bal_smote_model.fit(X_train_smote, y_train_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZz6PqstL5HA"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Te4FbTIDL5HA"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = dt_bal_smote_model.predict(X_train_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyr3udLOL5HA"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_smote, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txsUtwoTL5HA"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mF5yU44sL5HA"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_smote, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-izBATlL5HA"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_smote, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYFvm3JQL5HA"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = dt_bal_smote_model.predict_proba(X_train_smote)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TV-pxa2RL5HA"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_smote, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ef5FplPL5HA"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_smote, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV1ZyEpAL5HB"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_OfpKzdL5HB"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = dt_bal_smote_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paHxrL74L5HB"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LGcMXRJL5HB"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9S6wr70L5HB"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X21Snux-L5HB"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNt8F3K4L5HB"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = dt_bal_smote_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9Hvu8PKL5HB"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5F7rLq4eL5HB"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVWwwkN6L5HB"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.99\n",
        "    - Specificity = 0.98\n",
        "    - ROC-AUC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.98\n",
        "    - Sensitivity = 0.80\n",
        "    - Specificity = 0.98\n",
        "    - ROC-AUC = 0.86\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqddwBxxu6hN"
      },
      "outputs": [],
      "source": [
        "## AdaSyn (Adaptive Synthetic Sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgeY_3Dpu6hP"
      },
      "outputs": [],
      "source": [
        "# Importing adasyn\n",
        "from imblearn.over_sampling import ADASYN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hatzy4hSu6hQ"
      },
      "outputs": [],
      "source": [
        "# Instantiate adasyn\n",
        "ada = ADASYN(random_state=0)\n",
        "X_train_adasyn, y_train_adasyn = ada.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIauKd9CL5HC"
      },
      "outputs": [],
      "source": [
        "# Befor sampling class distribution\n",
        "print('Before sampling class distribution:-',Counter(y_train))\n",
        "# new class distribution \n",
        "print('New class distribution:-',Counter(y_train_adasyn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xb1TqCdL5HC"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Ruphs_L5HC"
      },
      "outputs": [],
      "source": [
        "# Creating KFold object with 3 splits\n",
        "folds = KFold(n_splits=3, shuffle=True, random_state=4)\n",
        "\n",
        "# Specify params\n",
        "params = {\"C\": [0.01, 0.1, 1, 10, 100, 1000]}\n",
        "\n",
        "# Specifing score as roc-auc\n",
        "model_cv = GridSearchCV(estimator = LogisticRegression(),\n",
        "                        param_grid = params, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True) \n",
        "\n",
        "# Fit the model\n",
        "model_cv.fit(X_train_adasyn, y_train_adasyn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O8ZA9ZIL5HC"
      },
      "outputs": [],
      "source": [
        "# results of grid search CV\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHsLwwdcL5HC"
      },
      "outputs": [],
      "source": [
        "# plot of C versus train and validation scores\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_test_score'])\n",
        "plt.plot(cv_results['param_C'], cv_results['mean_train_score'])\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('roc_auc')\n",
        "plt.legend(['test result', 'train result'], loc='upper left')\n",
        "plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzaPxflvL5HC"
      },
      "outputs": [],
      "source": [
        "# Best score with best C\n",
        "best_score = model_cv.best_score_\n",
        "best_C = model_cv.best_params_['C']\n",
        "\n",
        "print(\" The highest test roc_auc is {0} at C = {1}\".format(best_score, best_C))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGftRtrdL5HC"
      },
      "source": [
        "#### Logistic regression with optimal C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_5dQRNEL5HD"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model with best C\n",
        "logistic_bal_adasyn = LogisticRegression(C=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClANcaxYL5HD"
      },
      "outputs": [],
      "source": [
        "# Fit the model on the train set\n",
        "logistic_bal_adasyn_model = logistic_bal_adasyn.fit(X_train_adasyn, y_train_adasyn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3vBjKOTL5HD"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4D4APBaTL5HD"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = logistic_bal_adasyn_model.predict(X_train_adasyn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3YoVASnL5HD"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_adasyn, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3XUBzD8L5HD"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "666g4w02L5HD"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_adasyn, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))\n",
        "\n",
        "# F1 score\n",
        "print(\"F1-Score:-\", f1_score(y_train_adasyn, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pizrRzriL5HD"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_adasyn, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBlJ0MrLL5HD"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = logistic_bal_adasyn_model.predict_proba(X_train_adasyn)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr96fSuHL5HD"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_adasyn, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcUWQWX0L5HE"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_adasyn, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ21NXOWL5HE"
      },
      "source": [
        "#### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDA-DeiZL5HE"
      },
      "outputs": [],
      "source": [
        "# Prediction on the test set\n",
        "y_test_pred = logistic_bal_adasyn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEArCyNSL5HE"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCZLX26ML5HE"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uBdQpeHL5HE"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPiR_IiaL5HE"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62Wv_CrIL5HE"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = logistic_bal_adasyn_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3DBCAmxL5HE"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN4h-oCRL5HE"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puNZRoIBL5HF"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.88\n",
        "    - Sensitivity = 0.86\n",
        "    - Specificity = 0.91\n",
        "    - ROC = 0.96\n",
        "- Test set\n",
        "    - Accuracy = 0.90\n",
        "    - Sensitivity = 0.95\n",
        "    - Specificity = 0.90\n",
        "    - ROC = 0.97"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krX3aN4NL5HF"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2haukd7YL5HF"
      },
      "outputs": [],
      "source": [
        "# Create the parameter grid \n",
        "param_grid = {\n",
        "    'max_depth': range(5, 15, 5),\n",
        "    'min_samples_leaf': range(50, 150, 50),\n",
        "    'min_samples_split': range(50, 150, 50),\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the grid search model\n",
        "dtree = DecisionTreeClassifier()\n",
        "\n",
        "grid_search = GridSearchCV(estimator = dtree, \n",
        "                           param_grid = param_grid, \n",
        "                           scoring= 'roc_auc',\n",
        "                           cv = 3, \n",
        "                           verbose = 1)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train_adasyn,y_train_adasyn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pf6gO-8GL5HF"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0_1PX14L5HF"
      },
      "outputs": [],
      "source": [
        "# Printing the optimal sensitivity score and hyperparameters\n",
        "print(\"Best roc_auc:-\", grid_search.best_score_)\n",
        "print(grid_search.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8ezl6EBL5HF"
      },
      "outputs": [],
      "source": [
        "# Model with optimal hyperparameters\n",
        "dt_bal_adasyn_model = DecisionTreeClassifier(criterion = \"gini\", \n",
        "                                  random_state = 100,\n",
        "                                  max_depth=10, \n",
        "                                  min_samples_leaf=100,\n",
        "                                  min_samples_split=50)\n",
        "\n",
        "dt_bal_adasyn_model.fit(X_train_adasyn, y_train_adasyn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMfuimooL5HF"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpEhn9pmL5HF"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = dt_bal_adasyn_model.predict(X_train_adasyn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWjMDRBHL5HF"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_adasyn, y_train_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWNcYlvPL5HG"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKnvg3zCL5HG"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_adasyn, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6n0WahcL5HJ"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_adasyn, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-yTOEEAL5HJ"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = dt_bal_adasyn_model.predict_proba(X_train_adasyn)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vn4bkn9L5HJ"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_adasyn, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOhRevr9L5HJ"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_adasyn, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlt1WlBWL5HK"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh9asgCiL5HK"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = dt_bal_adasyn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBZ6eDNJL5HK"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vdgAYxxL5HK"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwVNkGIBL5HK"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ0MepslL5HK"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXQonZfzL5HK"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = dt_bal_adasyn_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-56eMB3L5HK"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq1axKOCL5HL"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_N1EatkL5HL"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.97\n",
        "    - Sensitivity = 0.99\n",
        "    - Specificity = 0.95\n",
        "    - ROC-AUC = 0.99\n",
        "- Test set\n",
        "    - Accuracy = 0.95\n",
        "    - Sensitivity = 0.84\n",
        "    - Specificity = 0.95\n",
        "    - ROC-AUC = 0.91"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPx6kZvYL5HL"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN2WqK7FL5HL"
      },
      "outputs": [],
      "source": [
        "# hyperparameter tuning with XGBoost\n",
        "\n",
        "# creating a KFold object \n",
        "folds = 3\n",
        "\n",
        "# specify range of hyperparameters\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]}          \n",
        "\n",
        "\n",
        "# specify model\n",
        "xgb_model = XGBClassifier(max_depth=2, n_estimators=200)\n",
        "\n",
        "# set up GridSearchCV()\n",
        "model_cv = GridSearchCV(estimator = xgb_model, \n",
        "                        param_grid = param_grid, \n",
        "                        scoring= 'roc_auc', \n",
        "                        cv = folds, \n",
        "                        verbose = 1,\n",
        "                        return_train_score=True)      \n",
        "\n",
        "# fit the model\n",
        "model_cv.fit(X_train_adasyn, y_train_adasyn)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyrVMAKML5HL"
      },
      "outputs": [],
      "source": [
        "# cv results\n",
        "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
        "cv_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yixWCwh1L5HL"
      },
      "outputs": [],
      "source": [
        "# # plotting\n",
        "plt.figure(figsize=(16,6))\n",
        "\n",
        "param_grid = {'learning_rate': [0.2, 0.6], \n",
        "             'subsample': [0.3, 0.6, 0.9]} \n",
        "\n",
        "\n",
        "for n, subsample in enumerate(param_grid['subsample']):\n",
        "    \n",
        "\n",
        "    # subplot 1/n\n",
        "    plt.subplot(1,len(param_grid['subsample']), n+1)\n",
        "    df = cv_results[cv_results['param_subsample']==subsample]\n",
        "\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n",
        "    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n",
        "    plt.xlabel('learning_rate')\n",
        "    plt.ylabel('AUC')\n",
        "    plt.title(\"subsample={0}\".format(subsample))\n",
        "    plt.ylim([0.60, 1])\n",
        "    plt.legend(['test score', 'train score'], loc='upper left')\n",
        "    plt.xscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0UdddrML5HL"
      },
      "outputs": [],
      "source": [
        "model_cv.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmLFEkCZL5HL"
      },
      "outputs": [],
      "source": [
        "# chosen hyperparameters\n",
        "\n",
        "params = {'learning_rate': 0.6,\n",
        "          'max_depth': 2, \n",
        "          'n_estimators':200,\n",
        "          'subsample':0.3,\n",
        "         'objective':'binary:logistic'}\n",
        "\n",
        "# fit model on training data\n",
        "xgb_bal_adasyn_model = XGBClassifier(params = params)\n",
        "xgb_bal_adasyn_model.fit(X_train_adasyn, y_train_adasyn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJiJXkvOL5HL"
      },
      "source": [
        "##### Prediction on the train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQZH6riL5HL"
      },
      "outputs": [],
      "source": [
        "# Predictions on the train set\n",
        "y_train_pred = xgb_bal_adasyn_model.predict(X_train_adasyn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plxnxkrlL5HL"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_train_adasyn, y_train_adasyn)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDP51SXyL5HM"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L08mq3qdL5HM"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_train_adasyn, y_train_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvkPOBd0L5HM"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_train_adasyn, y_train_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb_1pFNSL5HM"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_train_pred_proba = xgb_bal_adasyn_model.predict_proba(X_train_adasyn)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBssxHaiL5HM"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_train_adasyn, y_train_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y07kiLSjL5HM"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_train_adasyn, y_train_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xdZQI2BL5HM"
      },
      "source": [
        "##### Prediction on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIZRdykeL5HM"
      },
      "outputs": [],
      "source": [
        "# Predictions on the test set\n",
        "y_test_pred = xgb_bal_adasyn_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtdbXUvbL5HM"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix\n",
        "confusion = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icsRYZdmL5HM"
      },
      "outputs": [],
      "source": [
        "TP = confusion[1,1] # true positive \n",
        "TN = confusion[0,0] # true negatives\n",
        "FP = confusion[0,1] # false positives\n",
        "FN = confusion[1,0] # false negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUckX0LfL5HM"
      },
      "outputs": [],
      "source": [
        "# Accuracy\n",
        "print(\"Accuracy:-\",metrics.accuracy_score(y_test, y_test_pred))\n",
        "\n",
        "# Sensitivity\n",
        "print(\"Sensitivity:-\",TP / float(TP+FN))\n",
        "\n",
        "# Specificity\n",
        "print(\"Specificity:-\", TN / float(TN+FP))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UTRSjUeL5HN"
      },
      "outputs": [],
      "source": [
        "# classification_report\n",
        "print(classification_report(y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wdjQsvZL5HN"
      },
      "outputs": [],
      "source": [
        "# Predicted probability\n",
        "y_test_pred_proba = xgb_bal_adasyn_model.predict_proba(X_test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oeBo7SQL5HN"
      },
      "outputs": [],
      "source": [
        "# roc_auc\n",
        "auc = metrics.roc_auc_score(y_test, y_test_pred_proba)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPM88YrxL5HN"
      },
      "outputs": [],
      "source": [
        "# Plot the ROC curve\n",
        "draw_roc(y_test, y_test_pred_proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSWaii4kL5HN"
      },
      "source": [
        "***Model summary***\n",
        "\n",
        "- Train set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 1.0\n",
        "    - Specificity = 1.0\n",
        "    - ROC-AUC = 1.0\n",
        "- Test set\n",
        "    - Accuracy = 0.99\n",
        "    - Sensitivity = 0.78\n",
        "    - Specificity = 0.99\n",
        "    - ROC-AUC = 0.96"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIXbqq_L5HN"
      },
      "source": [
        "### Choosing best model on the balanced data\n",
        "\n",
        "He we balanced the data with various approach such as Undersampling, Oversampling, SMOTE and Adasy. With every data balancing thechnique we built several models such as Logistic, XGBoost, Decision Tree, and Random Forest.\n",
        "\n",
        "We can see that almost all the models performed more or less good. But we should be interested in the best model. \n",
        "\n",
        "Though the Undersampling technique models performed well, we should keep mind that by doing the undersampling some imformation were lost. Hence, it is better not to consider the undersampling models.\n",
        "\n",
        "Whereas the SMOTE and Adasyn models performed well. Among those models the simplist model Logistic regression has ROC score 0.99 in the train set and 0.97 on the test set. We can consider the Logistic model as the best model to choose because of the easy interpretation of the models and also the resourse requirements to build the mdoel is lesser than the other heavy models such as Random forest or XGBoost.\n",
        "\n",
        "Hence, we can conclude that the `Logistic regression model with SMOTE` is the best model for its simlicity and less resource requirement. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjvGSkqFL5HN"
      },
      "source": [
        "#### Print the FPR,TPR & select the best threshold from the roc curve for the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTj2H_pOL5HN"
      },
      "outputs": [],
      "source": [
        "print('Train auc =', metrics.roc_auc_score(y_train_smote, y_train_pred_proba_log_bal_smote))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_train_smote, y_train_pred_proba_log_bal_smote)\n",
        "threshold = thresholds[np.argmax(tpr-fpr)]\n",
        "print(\"Threshold=\",threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj38njYnL5HN"
      },
      "source": [
        "We can see that the threshold is 0.53, for which the TPR is the highest and FPR is the lowest and we got the best ROC score."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GfRG9UwjL5GU",
        "_W-CZRb7L5GU",
        "N0v_ynJiL5GU",
        "EDh_h9P7u6ay",
        "aj4qybydu6dy",
        "QAEpBkAnu6en",
        "GOTr0mCTL5Gi",
        "qNdhrQEku6ex",
        "ZpqYyzSiL5Gj",
        "2ijYmXCVL5Gj",
        "2M3L_IIzL5Gj",
        "1kpLV05Nu6e7",
        "DM6XPcYou6fE",
        "EaDTxEMlu6fe",
        "C6RacuWOu6fr",
        "ivgx2m8Iu6gg",
        "GZgGINh903AT",
        "J2Wwf_E8L5Gv",
        "UIQxTS0sL5Gx",
        "ryfKw-UdL5Gz",
        "mYGjuRlYL5G5",
        "jIFCgAVQL5G6",
        "thil7RGQL5G7",
        "Lu_ZSGP2L5G8",
        "NVSxH0ulL5G_",
        "6xb1TqCdL5HC",
        "TGftRtrdL5HC",
        "tZ21NXOWL5HE",
        "krX3aN4NL5HF",
        "ZPx6kZvYL5HL"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}